{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "dataset = input(\"Please type filename located in same folder): \")\n",
    "    \n",
    "col_names = []\n",
    "with open(dataset, 'r') as csvfile:\n",
    "    # creating csv reader\n",
    "    line = csv.reader(csvfile)\n",
    "     \n",
    "    # get field names in first row\n",
    "    col_names = next(line)\n",
    "\n",
    "#Get dataset\n",
    "#response = urllib.request.urlopen('https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data')\n",
    "#html = response.read()\n",
    "#soup = BeautifulSoup(html,\"lxml\")\n",
    "#body=soup.find_all('p')\n",
    "#txt_body=str(body)\n",
    "#txt_body=txt_body[4:-6]\n",
    "table_set=[]\n",
    "#for line in txt_body.splitlines():\n",
    "#    row=line.split(',')\n",
    "    #for ndx in range (len(row)):\n",
    "        #so we may check for null later...\n",
    "        #if(row[ndx]=='?'):\n",
    "            #row[ndx]=None\n",
    "            \n",
    "    #table_set.append(row)\n",
    "#len(table_set)\n",
    "#len(table_set[0])\n",
    "#col_names=['class','cap-shape','cap-surface','cap-color','bruises','odor','gill-attachment','gill-spacing',\\\n",
    "#            'gill-size','gill-color','stalk-shape','stalk-root','stalk-surface-above-ring','stalk-surface-below-ring', \\\n",
    "#             'stalk-color-above-ring', 'stalk-color-below-ring','viel-type','viel-color','ring-number','ring-type',\\\n",
    "#                'sport-print-color','population','habitat']\n",
    "           \n",
    "df = pd.DataFrame(table_set, columns=col_names)\n",
    "# get length of dataframe with len(df)\n",
    "# get specific row with df.iloc[i] where i is row number\n",
    "# get specific value from a specific row with df.iloc[i]['attribute'] where attribute is 'class', 'cap-shape', etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "raw_input() takes from 1 to 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-0396e3f6615c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Please type filename located in same folder)\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"(Note: Classifier should be in the first column and its column name should be class)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mcol_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: raw_input() takes from 1 to 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import scipy.stats as stats\n",
    "import random\n",
    "import math\n",
    "import csv\n",
    "import datetime\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dataset = input(\"Please type filename located in same folder)\\n(Note: Classifier should be in the first column and its column name should be class)\")\n",
    "    \n",
    "col_names = []\n",
    "with open(dataset, 'r') as csvfile:\n",
    "    # creating csv reader\n",
    "    line = csv.reader(csvfile)\n",
    "     \n",
    "    # get field names in first row\n",
    "    col_names = next(line)\n",
    "    \n",
    "df = pd.read_csv(dataset)\n",
    "#df.columns = col_names\n",
    "\n",
    "df = pd.DataFrame(df, columns=col_names)\n",
    "\n",
    "#Get dataset\n",
    "#response = urllib.request.urlopen('https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data')\n",
    "#html = response.read()\n",
    "#soup = BeautifulSoup(html,\"lxml\")\n",
    "#body=soup.find_all('p')\n",
    "#txt_body=str(body)\n",
    "#txt_body=txt_body[4:-6]\n",
    "table_set=[]\n",
    "#for line in txt_body.splitlines():\n",
    "#    row=line.split(',')\n",
    "    #for ndx in range (len(row)):\n",
    "        #so we may check for null later...\n",
    "        #if(row[ndx]=='?'):\n",
    "            #row[ndx]=None\n",
    "            \n",
    "    #table_set.append(row)\n",
    "#len(table_set)\n",
    "#len(table_set[0])\n",
    "#col_names=['class','cap-shape','cap-surface','cap-color','bruises','odor','gill-attachment','gill-spacing',\\\n",
    "#            'gill-size','gill-color','stalk-shape','stalk-root','stalk-surface-above-ring','stalk-surface-below-ring', \\\n",
    "#             'stalk-color-above-ring', 'stalk-color-below-ring','viel-type','viel-color','ring-number','ring-type',\\\n",
    "#                'sport-print-color','population','habitat']\n",
    "           \n",
    "#df = pd.DataFrame(table_set, columns=col_names)\n",
    "# get length of dataframe with len(df)\n",
    "# get specific row with df.iloc[i] where i is row number\n",
    "# get specific value from a specific row with df.iloc[i]['attribute'] where attribute is 'class', 'cap-shape', etc\n",
    "\n",
    "\n",
    "Attbs = col_names[1:]\n",
    "\n",
    "def splitDataset(dataf, splitRatio):\n",
    "    trainSize = int(len(dataf) * splitRatio)\n",
    "    testSize = int(len(dataf) * (1 - splitRatio))\n",
    "    trainSet = []\n",
    "    testSet = []\n",
    "    df2 = pd.DataFrame(table_set, columns=col_names)\n",
    "    while len(trainSet) < trainSize:\n",
    "        #index = f.iloc[random.randrange(len(copy))]\n",
    "        trainSet.append(dataf.iloc[random.randrange(len(dataf))])\n",
    "    while len((testSet)) < testSize:\n",
    "        testSet.append(dataf.iloc[random.randrange(len(dataf))])\n",
    "    return [trainSet, testSet]\n",
    "    \n",
    "\n",
    "#create classifier count dictionary\n",
    "def findClass(train):\n",
    "    dict = {}\n",
    "    for i in range(0,len(train)):\n",
    "        if train.iloc[i][0] not in dict.keys():\n",
    "            dict[train.iloc[i][0]] = 0\n",
    "        else:\n",
    "            dict[train.iloc[i][0]] += 1\n",
    "    return dict\n",
    "\n",
    "def fit(train, classifier):\n",
    "    dict = {}\n",
    "    Attbs = col_names[1:]\n",
    "    labels = train['class'].unique\n",
    "    #lab = e, p\n",
    "    #for lab in labels:\n",
    "    dfi = train.where(df['class'] == classifier).dropna() #classifier\n",
    "    counterVar = 1;\n",
    "    for attb in Attbs:\n",
    "        subDict = {}\n",
    "        classAndCountSeries = dfi[attb].value_counts()\n",
    "        subClass = classAndCountSeries.index.values\n",
    "        subCount = classAndCountSeries.values\n",
    "        for i in range(0,len(subClass)):\n",
    "            subDict[subClass[i]]= subCount[i]\n",
    "        dict[counterVar] = subDict\n",
    "        counterVar = counterVar + 1\n",
    "        #print(subClass, subCount)\n",
    "        #print(\"%s:\\n\" % (attb), cnts)\n",
    "    return dict\n",
    "\n",
    "def getProbability(finalDict, classD):\n",
    "    Attbs = col_names[1:]\n",
    "    for bigKey in finalDict.keys():\n",
    "        for i in range(1, len(col_names)):\n",
    "            for key in finalDict[bigKey][i].keys():\n",
    "                finalDict[bigKey][i][key] /= classD[bigKey]\n",
    "    return finalDict\n",
    "\n",
    "def returnClassifier(someDict):\n",
    "    trackVal = 0\n",
    "    trackVar = \"false\"\n",
    "    for key in someDict.keys():\n",
    "        if someDict[key] > 0:\n",
    "            returnVal = someDict[key]\n",
    "            trackVar = key\n",
    "    return key\n",
    "            \n",
    "def getResults(finalDict, testData, classDict, trainTotal):\n",
    "    returnCount = 0\n",
    "    totalTuples = len(testData)\n",
    "    #traverse test data\n",
    "    for i in range(0, len(testData)):\n",
    "        #traverse attributes in testData\n",
    "        subDict = {}\n",
    "        for finalKey in finalDict.keys():\n",
    "            tupleProbability = 1\n",
    "            for j in range(1, len(col_names)):\n",
    "            #getprobabilities\n",
    "                subKey = testData.iloc[i][j]\n",
    "                if subKey not in finalDict[finalKey][j].keys():\n",
    "                    tupleProbability = 0\n",
    "                    continue\n",
    "                tupleProbability *= finalDict[finalKey][j][testData.iloc[i][j]]\n",
    "            tupleProbability *= (classDict[finalKey] / trainTotal)\n",
    "            subDict[finalKey] = tupleProbability    \n",
    "        classifierIs = returnClassifier(subDict)\n",
    "        if classifierIs == testData.iloc[i][0]:\n",
    "            returnCount += 1\n",
    "        if i == 0:\n",
    "            print(\"    Start calculations:\", datetime.datetime.now())\n",
    "        if i == (len(testData) - 1):\n",
    "            print(\"    End calculations:\", datetime.datetime.now())\n",
    "    print(\"    Total tests:\", totalTuples, \"    Correctly predicted:\", returnCount)\n",
    "    print(\"    Percent accuracy:\", returnCount/totalTuples * 100, \"percent\")\n",
    "\n",
    "def driver():\n",
    "    print(\"Start driver: \", datetime.datetime.now())\n",
    "    splitRatio = 0.67\n",
    "    trainingSet, testSet = splitDataset(df, splitRatio)\n",
    "    trainingSet = pd.DataFrame(trainingSet, columns=col_names)\n",
    "    trainingSet.sort_index(inplace=True)\n",
    "    testSet = pd.DataFrame(testSet, columns=col_names)\n",
    "    testSet.sort_index(inplace=True)\n",
    "    #get totals for each class and place it into dictionary\n",
    "    classDict = findClass(trainingSet)\n",
    "    trainTotal = 0\n",
    "    for key in classDict.keys():\n",
    "        trainTotal += classDict[key]\n",
    "    \n",
    "    #prepare nested dictionary\n",
    "    colDict = {}\n",
    "    for key in classDict.keys():\n",
    "        colDict[key] = fit(trainingSet, key)\n",
    "    #test print colDict\n",
    "    #for key, values in colDict.items():\n",
    "    #   print(key, values, \"\\n\")\n",
    "    #print(colDict['p']['cap-shape']['x'])\n",
    "    finalDict = getProbability(colDict, classDict)\n",
    "    #test print finalDict\n",
    "    #for key, values in finalDict.items():\n",
    "    #    print(key, values, \"\\n\")\n",
    "    #print(finalDict['p']['cap-shape']['x']) #test print nested value\n",
    "    #print(testSet.iloc[1]['cap-shape'])\n",
    "    print(\"  Training data ratio:\", splitRatio)\n",
    "    getResults(finalDict, testSet, classDict, trainTotal)\n",
    "    \n",
    "    print(\"  Start k-fold: \", datetime.datetime.now())\n",
    "    \n",
    "    #k-fold\n",
    "    for i in range(0, 5):\n",
    "        #Each instance is each fold\n",
    "        print(\"  Fold\",i+1)\n",
    "        #Train:\n",
    "        ktrainingSet, ktestSet = splitDataset(df, splitRatio/5)\n",
    "        ktrainingSet = pd.DataFrame(ktrainingSet, columns=col_names)\n",
    "        ktrainingSet.sort_index(inplace=True)\n",
    "        kclassDict = findClass(ktrainingSet)\n",
    "        ktotal = 0\n",
    "        for key in kclassDict.keys():\n",
    "            ktotal += kclassDict[key]\n",
    "        kcolDict = {}\n",
    "        for key in classDict.keys():\n",
    "            kcolDict[key] = fit(ktrainingSet, key)\n",
    "        kfinalDict = getProbability(kcolDict, classDict)\n",
    "        #Predict:\n",
    "        getResults(kfinalDict, testSet, kclassDict, ktotal)\n",
    "    \n",
    "    print(\"  End k-fold: \", datetime.datetime.now())\n",
    "    \n",
    "    print(\"End Driver: \", datetime.datetime.now())\n",
    "    \n",
    "driver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
